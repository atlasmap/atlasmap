<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>KafkaConnectModule.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">Unit Test Coverage Report</a> &gt; <a href="../index.html" class="el_bundle">atlas-kafka-connect-module</a> &gt; <a href="index.source.html" class="el_package">io.atlasmap.kafkaconnect.module</a> &gt; <span class="el_source">KafkaConnectModule.java</span></div><h1>KafkaConnectModule.java</h1><pre class="source lang-java linenums">/*
 * Copyright (C) 2017 Red Hat, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package io.atlasmap.kafkaconnect.module;

import java.util.HashMap;
import java.util.List;

import org.apache.kafka.connect.data.Schema.Type;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import io.atlasmap.api.AtlasException;
import io.atlasmap.api.AtlasValidationException;
import io.atlasmap.core.AtlasPath;
import io.atlasmap.core.AtlasUtil;
import io.atlasmap.core.BaseAtlasModule;
import io.atlasmap.kafkaconnect.core.KafkaConnectFieldReader;
import io.atlasmap.kafkaconnect.core.KafkaConnectFieldWriter;
import io.atlasmap.kafkaconnect.core.KafkaConnectUtil;
import io.atlasmap.kafkaconnect.v2.AtlasKafkaConnectModelFactory;
import io.atlasmap.kafkaconnect.v2.KafkaConnectConstants;
import io.atlasmap.kafkaconnect.v2.KafkaConnectEnumField;
import io.atlasmap.kafkaconnect.v2.KafkaConnectField;
import io.atlasmap.kafkaconnect.v2.KafkaConnectSchemaType;
import io.atlasmap.spi.AtlasInternalSession;
import io.atlasmap.spi.AtlasModuleDetail;
import io.atlasmap.v2.AtlasModelFactory;
import io.atlasmap.v2.AuditStatus;
import io.atlasmap.v2.DataSourceMetadata;
import io.atlasmap.v2.Field;
import io.atlasmap.v2.FieldGroup;
import io.atlasmap.v2.Validation;
import io.atlasmap.v2.Validations;

/**
 * The {@link io.atlasmap.spi.AtlasModule} implementation for Kafka Connect.
 */
@AtlasModuleDetail(name = &quot;KafkaConnectModule&quot;, uri = &quot;atlas:kafkaconnect&quot;, modes = { &quot;SOURCE&quot;, &quot;TARGET&quot; }, dataFormats = {
        &quot;kafkaconnect&quot; }, configPackages = { &quot;io.atlasmap.kafkaconnect.v2&quot; })
<span class="fc" id="L53">public class KafkaConnectModule extends BaseAtlasModule {</span>
<span class="fc" id="L54">    private static final Logger LOG = LoggerFactory.getLogger(KafkaConnectModule.class);</span>

    private boolean isKey;
    private Type rootSchemaType;

    @Override
    public void init() throws AtlasException {
<span class="nc" id="L61">        super.init();</span>
<span class="nc" id="L62">        String typeStr = AtlasUtil.unescapeFromUri(AtlasUtil.getUriParameterValue(getUri(), &quot;rootSchemaType&quot;));</span>
<span class="nc bnc" id="L63" title="All 2 branches missed.">        rootSchemaType = typeStr != null ? Type.valueOf(typeStr) : Type.STRUCT;</span>
<span class="nc" id="L64">        String isKeyStr = AtlasUtil.unescapeFromUri(AtlasUtil.getUriParameterValue(getUri(), &quot;isKey&quot;));</span>
<span class="nc bnc" id="L65" title="All 2 branches missed.">        isKey = isKeyStr != null ? Boolean.parseBoolean(isKeyStr) : false;</span>
<span class="nc" id="L66">    }</span>

    @Override
    public void processPreValidation(AtlasInternalSession session) throws AtlasException {
<span class="nc bnc" id="L70" title="All 4 branches missed.">        if (session == null || session.getMapping() == null) {</span>
<span class="nc" id="L71">            throw new AtlasValidationException(&quot;Invalid session: Session and AtlasMapping must be specified&quot;);</span>
        }

<span class="nc" id="L74">        Validations validations = session.getValidations();</span>
<span class="nc" id="L75">        KafkaConnectValidationService kafkaConnectValidationService = new KafkaConnectValidationService(getConversionService(), getFieldActionService());</span>
<span class="nc" id="L76">        kafkaConnectValidationService.setMode(getMode());</span>
<span class="nc" id="L77">        kafkaConnectValidationService.setDocId(getDocId());</span>
<span class="nc" id="L78">        List&lt;Validation&gt; kafkaConnectValidations = kafkaConnectValidationService.validateMapping(session.getMapping());</span>
<span class="nc bnc" id="L79" title="All 4 branches missed.">        if (kafkaConnectValidations != null &amp;&amp; !kafkaConnectValidations.isEmpty()) {</span>
<span class="nc" id="L80">            validations.getValidation().addAll(kafkaConnectValidations);</span>
        }

<span class="nc bnc" id="L83" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L84">            LOG.debug(&quot;Detected &quot; + kafkaConnectValidations.size() + &quot; json validation notices&quot;);</span>
        }

<span class="nc bnc" id="L87" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L88">            LOG.debug(&quot;{}: processPreValidation completed&quot;, getDocId());</span>
        }
<span class="nc" id="L90">    }</span>

    @Override
    public void processPreSourceExecution(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L94">        Object sourceDocument = session.getSourceDocument(getDocId());</span>
<span class="nc" id="L95">        KafkaConnectFieldReader fieldReader = new KafkaConnectFieldReader(getConversionService());</span>
<span class="nc" id="L96">        fieldReader.setDocument(sourceDocument);</span>
<span class="nc" id="L97">        fieldReader.setSchema(extractSchema(getDataSourceMetadata()));</span>
<span class="nc" id="L98">        session.setFieldReader(getDocId(), fieldReader);</span>

<span class="nc bnc" id="L100" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L101">            LOG.debug(&quot;{} processPreSourceExcution completed&quot;, getDocId());</span>
        }
<span class="nc" id="L103">    }</span>

    private org.apache.kafka.connect.data.Schema extractSchema(DataSourceMetadata meta) throws AtlasException {
<span class="nc bnc" id="L106" title="All 4 branches missed.">        if (meta == null || meta.getSpecification() == null) {</span>
<span class="nc" id="L107">            return null;</span>
        }
<span class="nc" id="L109">        byte[] bytes = meta.getSpecification();</span>
<span class="nc" id="L110">        String schema = new String(bytes);</span>
<span class="nc" id="L111">        String typeStr = meta.getInspectionParameters().get(KafkaConnectConstants.OPTIONS_SCHEMA_TYPE);</span>
<span class="nc" id="L112">        KafkaConnectSchemaType type = KafkaConnectSchemaType.valueOf(typeStr);</span>
<span class="nc" id="L113">        HashMap&lt;String, Object&gt; options = KafkaConnectUtil.repackParserOptions(meta.getInspectionParameters());</span>
        try {
<span class="nc bnc" id="L115" title="All 3 branches missed.">            switch (type) {</span>
                case JSON:
<span class="nc" id="L117">                    return KafkaConnectUtil.parseJson(schema, options);</span>
                case AVRO:
<span class="nc" id="L119">                    return KafkaConnectUtil.parseAvro(schema, options);</span>
                default:
<span class="nc" id="L121">                    LOG.warn(&quot;Ignoring unsupported KafkaConnect schema type '{}'&quot;, type);</span>
<span class="nc" id="L122">                    return null;</span>
            }
<span class="nc" id="L124">        } catch (Exception e) {</span>
<span class="nc" id="L125">            throw new AtlasException(e);</span>
        }
    }

    @Override
    public void processPreTargetExecution(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L131">        KafkaConnectFieldWriter writer = new KafkaConnectFieldWriter(getConversionService());</span>
<span class="nc" id="L132">        writer.setSchema(extractSchema(getDataSourceMetadata()));</span>
<span class="nc" id="L133">        session.setFieldWriter(getDocId(), writer);</span>

<span class="nc bnc" id="L135" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L136">            LOG.debug(&quot;{} processPreTargetExcution completed&quot;, getDocId());</span>
        }
        
<span class="nc" id="L139">    }</span>

    @Override
    public void readSourceValue(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L143">        Field sourceField = session.head().getSourceField();</span>
<span class="nc" id="L144">        KafkaConnectFieldReader reader = session.getFieldReader(getDocId(), KafkaConnectFieldReader.class);</span>
<span class="nc bnc" id="L145" title="All 2 branches missed.">        if (reader == null) {</span>
<span class="nc" id="L146">            AtlasUtil.addAudit(session, sourceField, String.format(</span>
<span class="nc" id="L147">                    &quot;Source document '%s' doesn't exist&quot;, getDocId()),</span>
                    AuditStatus.ERROR, null);
<span class="nc" id="L149">            return;</span>
        }
<span class="nc" id="L151">        reader.read(session);</span>

<span class="nc bnc" id="L153" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L154">            LOG.debug(&quot;{}: processSourceFieldMapping completed: SourceField:[docId={}, path={}, type={}, value={}]&quot;,</span>
<span class="nc" id="L155">                    getDocId(), sourceField.getDocId(), sourceField.getPath(), sourceField.getFieldType(),</span>
<span class="nc" id="L156">                    sourceField.getValue());</span>
        }
<span class="nc" id="L158">    }</span>

    @Override
    public void populateTargetField(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L162">        Field sourceField = session.head().getSourceField();</span>
<span class="nc" id="L163">        Field targetField = session.head().getTargetField();</span>
<span class="nc" id="L164">        AtlasPath path = new AtlasPath(targetField.getPath());</span>
<span class="nc" id="L165">        FieldGroup targetFieldGroup = null;</span>
<span class="nc bnc" id="L166" title="All 4 branches missed.">        if (path.hasCollection() &amp;&amp; !path.isIndexedCollection()) {</span>
<span class="nc" id="L167">            targetFieldGroup = AtlasModelFactory.createFieldGroupFrom(targetField, true);</span>
<span class="nc" id="L168">            session.head().setTargetField(targetFieldGroup);</span>
        }

        // Attempt to Auto-detect field type based on input value
<span class="nc bnc" id="L172" title="All 4 branches missed.">        if (targetField.getFieldType() == null &amp;&amp; sourceField.getValue() != null) {</span>
<span class="nc" id="L173">            targetField.setFieldType(getConversionService().fieldTypeFromClass(sourceField.getValue().getClass()));</span>
        }

<span class="nc bnc" id="L176" title="All 2 branches missed.">        if (targetFieldGroup == null) {</span>
<span class="nc bnc" id="L177" title="All 2 branches missed.">            if (sourceField instanceof FieldGroup) {</span>
<span class="nc" id="L178">                List&lt;Field&gt; subFields = ((FieldGroup)sourceField).getField();</span>
<span class="nc bnc" id="L179" title="All 4 branches missed.">                if (subFields != null &amp;&amp; subFields.size() &gt; 0) {</span>
<span class="nc" id="L180">                    Integer index = targetField.getIndex();</span>
<span class="nc bnc" id="L181" title="All 2 branches missed.">                    if (index != null) {</span>
<span class="nc bnc" id="L182" title="All 2 branches missed.">                        if (subFields.size() &gt; index) {</span>
<span class="nc" id="L183">                            sourceField = subFields.get(index);</span>
                        } else {
<span class="nc" id="L185">                            AtlasUtil.addAudit(session, getDocId(), String.format(</span>
                                    &quot;The number of source fields (%s) is smaller than target index (%s) - ignoring&quot;,
<span class="nc" id="L187">                                    subFields.size(), index),</span>
                                    AuditStatus.WARN, null);
<span class="nc" id="L189">                            return;</span>
                        }
                    } else {
                        // The last one wins for compatibility
<span class="nc" id="L193">                        sourceField = subFields.get(subFields.size() - 1);</span>
                    }
<span class="nc" id="L195">                    session.head().setSourceField(sourceField);</span>
                }
            }
<span class="nc" id="L198">            super.populateTargetField(session);</span>
<span class="nc bnc" id="L199" title="All 2 branches missed.">        } else if (sourceField instanceof FieldGroup) {</span>
<span class="nc" id="L200">            Field previousTargetSubField = null;</span>
<span class="nc bnc" id="L201" title="All 2 branches missed.">            for (int i=0; i&lt;((FieldGroup)sourceField).getField().size(); i++) {</span>
<span class="nc" id="L202">                Field sourceSubField = ((FieldGroup)sourceField).getField().get(i);</span>
<span class="nc" id="L203">                KafkaConnectField targetSubField = AtlasKafkaConnectModelFactory.createKafkaConnectField();</span>
<span class="nc" id="L204">                AtlasKafkaConnectModelFactory.copyField(targetField, targetSubField, false);</span>
<span class="nc" id="L205">                getCollectionHelper().copyCollectionIndexes(sourceField, sourceSubField, targetSubField, previousTargetSubField);</span>
<span class="nc" id="L206">                previousTargetSubField = targetSubField;</span>
<span class="nc" id="L207">                targetFieldGroup.getField().add(targetSubField);</span>
<span class="nc" id="L208">                session.head().setSourceField(sourceSubField);</span>
<span class="nc" id="L209">                session.head().setTargetField(targetSubField);</span>
<span class="nc" id="L210">                super.populateTargetField(session);</span>
            }
<span class="nc" id="L212">            session.head().setSourceField(sourceField);</span>
<span class="nc" id="L213">            session.head().setTargetField(targetFieldGroup);</span>
<span class="nc" id="L214">        } else {</span>
<span class="nc" id="L215">            KafkaConnectField targetSubField = new KafkaConnectField();</span>
<span class="nc" id="L216">            AtlasKafkaConnectModelFactory.copyField(targetField, targetSubField, false);</span>
<span class="nc" id="L217">            path.setVacantCollectionIndex(0);</span>
<span class="nc" id="L218">            targetSubField.setPath(path.toString());</span>
<span class="nc" id="L219">            targetFieldGroup.getField().add(targetSubField);</span>
<span class="nc" id="L220">            session.head().setTargetField(targetSubField);</span>
<span class="nc" id="L221">            super.populateTargetField(session);</span>
<span class="nc" id="L222">            session.head().setTargetField(targetFieldGroup);</span>
        }

<span class="nc bnc" id="L225" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L226">            LOG.debug(</span>
                    &quot;{}: processTargetFieldMapping completed: SourceField:[docId={}, path={}, type={}, value={}], TargetField:[docId={}, path={}, type={}, value={}]&quot;,
<span class="nc" id="L228">                    getDocId(), sourceField.getDocId(), sourceField.getPath(), sourceField.getFieldType(),</span>
<span class="nc" id="L229">                    sourceField.getValue(), targetField.getDocId(), targetField.getPath(), targetField.getFieldType(),</span>
<span class="nc" id="L230">                    targetField.getValue());</span>
        }
<span class="nc" id="L232">    }</span>

    @Override
    public void writeTargetValue(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L236">        KafkaConnectFieldWriter writer = session.getFieldWriter(getDocId(), KafkaConnectFieldWriter.class);</span>
<span class="nc bnc" id="L237" title="All 2 branches missed.">        if (session.head().getTargetField() instanceof FieldGroup) {</span>
<span class="nc" id="L238">            FieldGroup targetFieldGroup = (FieldGroup) session.head().getTargetField();</span>
<span class="nc bnc" id="L239" title="All 2 branches missed.">            if (targetFieldGroup.getField().size() &gt; 0) {</span>
<span class="nc bnc" id="L240" title="All 2 branches missed.">                for (Field f : targetFieldGroup.getField()) {</span>
<span class="nc" id="L241">                    session.head().setTargetField(f);</span>
<span class="nc" id="L242">                    writer.write(session);</span>
<span class="nc" id="L243">                }</span>
<span class="nc" id="L244">                return;</span>
            }
        }
<span class="nc" id="L247">        writer.write(session);</span>
<span class="nc" id="L248">    }</span>

    @Override
    public void processPostSourceExecution(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L252">        session.removeFieldReader(getDocId());</span>

<span class="nc bnc" id="L254" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L255">            LOG.debug(&quot;{}: processPostSourceExecution completed&quot;, getDocId());</span>
        }
<span class="nc" id="L257">    }</span>

    @Override
    public void processPostTargetExecution(AtlasInternalSession session) throws AtlasException {
<span class="nc" id="L261">        KafkaConnectFieldWriter writer = session.getFieldWriter(getDocId(), KafkaConnectFieldWriter.class);</span>
<span class="nc bnc" id="L262" title="All 4 branches missed.">        if (writer != null &amp;&amp; writer.getDocument() != null) {</span>
<span class="nc" id="L263">            Object outputBody = writer.getDocument();</span>
<span class="nc" id="L264">            session.setTargetDocument(getDocId(), outputBody);</span>
<span class="nc" id="L265">        } else {</span>
<span class="nc" id="L266">            AtlasUtil.addAudit(session, getDocId(), String</span>
<span class="nc" id="L267">                    .format(&quot;No target document created for DataSource:[id=%s, uri=%s]&quot;, getDocId(), this.getUri()),</span>
                    AuditStatus.WARN, null);
        }
<span class="nc" id="L270">        session.removeFieldWriter(getDocId());</span>

<span class="nc bnc" id="L272" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L273">            LOG.debug(&quot;{}: processPostTargetExecution completed&quot;, getDocId());</span>
        }
<span class="nc" id="L275">    }</span>

    @Override
    public Boolean isSupportedField(Field field) {
<span class="fc bfc" id="L279" title="All 2 branches covered.">        if (super.isSupportedField(field)) {</span>
<span class="fc" id="L280">            return true;</span>
        }
<span class="fc bfc" id="L282" title="All 4 branches covered.">        return field instanceof KafkaConnectField || field instanceof KafkaConnectEnumField;</span>
    }

    @Override
    public Field cloneField(Field field) throws AtlasException {
<span class="nc" id="L287">        return AtlasKafkaConnectModelFactory.cloneField((KafkaConnectField)field, true);</span>
    }

    @Override
    public Field createField() {
<span class="nc" id="L292">        return AtlasKafkaConnectModelFactory.createKafkaConnectField();</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>